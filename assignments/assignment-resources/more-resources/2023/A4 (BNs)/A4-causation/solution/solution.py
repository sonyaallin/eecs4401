import random
import pandas as pd
from bnetbase import Variable, Factor, BN, restrict_factor, sum_out_variable, normalize

def multiply_factors(Factors):
    '''return a new factor that is the product of the factors in Fators'''
    scope = []
    for f in Factors:
        for v in f.get_scope():
            if not v in scope:
                scope.append(v)
    F = Factor("Product{}".format(Factors), scope)

    def recursive_multiply(Vars):
        if len(Vars) == 1:
            for val in Vars[0].domain():
                Vars[0].set_assignment(val)
                prod = 1
                for f in Factors:
                    prod = prod * f.get_value_at_current_assignments()
                F.add_value_at_current_assignment(prod)
        else:
            for val in Vars[0].domain():
                Vars[0].set_assignment(val)
                recursive_multiply(Vars[1:])

    recursive_multiply(scope)
    return F


###Orderings

def min_fill_ordering(Factors, QueryVar):
    '''Compute a min fill ordering given a list of factors. Return a list
    of variables from the scopes of the factors in Factors. The QueryVar is
    NOT part of the returned ordering'''
    scopes = []
    for f in Factors:
        scopes.append(list(f.get_scope()))
    Vars = []
    for s in scopes:
        for v in s:
            if not v in Vars and v != QueryVar:
                Vars.append(v)

    ordering = []
    while Vars:
        (var, new_scope) = min_fill_var(scopes, Vars)
        ordering.append(var)
        if var in Vars:
            Vars.remove(var)
        scopes = remove_var(var, new_scope, scopes)
    return ordering


def min_fill_var(scopes, Vars):
    '''Given a set of scopes (lists of lists of variables) compute and
    return the variable with minimum fill in. That the variable that
    generates a factor of smallest scope when eliminated from the set
    of scopes. Also return the new scope generated from eliminating
    that variable.'''

    minv = Vars[0]
    (minfill, min_new_scope) = compute_fill(scopes, Vars[0])
    for v in Vars[1:]:
        (fill, new_scope) = compute_fill(scopes, v)
        if fill < minfill:
            minv = v
            minfill = fill
            min_new_scope = new_scope
    return (minv, min_new_scope)


def compute_fill(scopes, var):
    '''Return the fill in scope generated by eliminating var from
    scopes along with the size of this new scope'''
    union = []
    for s in scopes:
        if var in s:
            for v in s:
                if not v in union:
                    union.append(v)
    if var in union: union.remove(var)
    return (len(union), union)


def remove_var(var, new_scope, scopes):
    '''Return the new set of scopes that arise from eliminating var
    from scopes'''

    new_scopes = []
    for s in scopes:
        if not var in s:
            new_scopes.append(s)
    new_scopes.append(new_scope)
    return new_scopes


###
def VE(Net, QueryVar, EvidenceVars):
    '''
    Input: Net---a BN object (a Bayes Net)
           QueryVar---a Variable object (the variable whose distribution
                      we want to compute)
           EvidenceVars---a LIST of Variable objects. Each of these
                          variables has had its evidence set to a particular
                          value from its domain using set_evidence.

   VE returns a distribution over the values of QueryVar, i.e., a list
   of numbers one for every value in QueryVar's domain. These numbers
   sum to one, and the i'th number is the probability that QueryVar is
   equal to its i'th value given the setting of the evidence
   variables. For example if QueryVar = A with Dom[A] = ['a', 'b',
   'c'], EvidenceVars = [B, C], and we have previously called
   B.set_evidence(1) and C.set_evidence('c'), then VE would return a
   list of three numbers. E.g. [0.5, 0.24, 0.26]. These numbers would
   mean that Pr(A='a'|B=1, C='c') = 0.5 Pr(A='a'|B=1, C='c') = 0.24
   Pr(A='a'|B=1, C='c') = 0.26

    '''
    Factors = Net.factors()  # note we get a copy so it is safe to modify this copy

    ##1. restrict by evidence
    for i in range(len(Factors)):
        f = Factors[i]
        newf = f
        for s in newf.get_scope():
            if s in EvidenceVars:
                newf = restrict_factor(newf, s, s.get_evidence())
                # note that a factor might get restricted multiple times.
        Factors[i] = newf  # replace the old factor

    ##compute min-fill ordering
    order = min_fill_ordering(Factors, QueryVar)

    for v in order:
        ##find factors over v
        v_factors = []
        for f in Factors:
            if v in f.get_scope():
                v_factors.append(f)
        # remove from list of factors
        for f in v_factors:
            Factors.remove(f)
        # eliminate v
        if len(v_factors) > 1:
            newf = multiply_factors(v_factors)
        else:
            newf = v_factors[0]
        newf = sum_out_variable(newf, v)
        Factors.append(newf)
    final_factor = multiply_factors(Factors)
    distribution = final_factor.values
    if sum(distribution) == 0:
        dist = [float('inf')] * len(distribution)
    else:
        dist = normalize(distribution)
    return (dist)


def CausalModelConfounder():
    '''
   CausalModelConfounder returns a DAG that is a Causal model that
   represents the joint distribution of value assignments to
   variables in COVID-19 data.
    '''
    ### READ IN THE DATA
    df = pd.read_csv('data/covid.csv')

    ### DOMAIN INFORMATION
    variable_domains = {
    "Age": ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80'],
    "Country": ['Italy', 'China'],
    "Fatality": ['YES', 'NO']
    }

    countC, countI, agesI, fatalitiesC, fatalitiesI = [], [], [], [], []

    for age in variable_domains["Age"]:
        countC.append(len(df[(df["Country"] == "China") & (df["Age"] == age)]))
        countI.append(len(df[(df["Country"] == "Italy") & (df["Age"] == age)]))
        agesI.append(countI[-1]/(countC[-1]+countI[-1])) #probability of Italy in each age bracket
        temp = len(df[(df["Country"] == "China") &
                     (df["Age"] == age)  &
                     (df["Fatality"] == "YES")])
        fatalitiesC.append(temp/countC[-1])
        temp = len(df[(df["Country"] == "Italy") &
                     (df["Age"] == age)  &
                     (df["Fatality"] == "YES")])
        fatalitiesI.append(temp/countI[-1])

    agesC = [1 - val for val in agesI]
    ages = agesI + agesC
    fatalitiesY = fatalitiesI + fatalitiesC
    fatalitiesN = [1 - val for val in fatalitiesY]
    fatalities = fatalitiesY + fatalitiesN

    A = Variable("Age", variable_domains["Age"])
    F0 = Factor("P(A)", [A])
    values = []
    for age in  variable_domains["Age"]: #all the ages are now priors
        values.append([age, len(df[(df["Age"] == age)])/df.shape[0]])
    F0.add_values(values)

    C = Variable("Country", variable_domains["Country"])
    F1 = Factor("P(C|A)", [C,A])
    #note probabilities that are initialized are bogus
    values = [['Italy', '0-9', 0.33], ['Italy', '10-19', 0.47], ['Italy', '20-29', 0.47], ['Italy', '30-39', 0.47], ['Italy', '40-49', 0.47], ['Italy', '50-59', 0.47], ['Italy', '60-69', 0.47], ['Italy', '70-79', 0.47], ['Italy', '80', 0.47],
              ['China', '0-9', 0.33], ['China', '10-19', 0.47], ['China', '20-29', 0.47], ['China', '30-39', 0.47], ['China', '40-49', 0.47], ['China', '50-59', 0.47], ['China', '60-69', 0.47], ['China', '70-79', 0.47], ['China', '80', 0.47]]
    for i in range(0,len(values)): #replace bogus values
        values[i][2] = ages[i]
    F1.add_values(values)

    F = Variable("Fatality", variable_domains["Fatality"])
    F2 = Factor("P(F|C,A)", [F,C,A])
    #note probabilities that are initialized are bogus
    values = [['YES', 'Italy', '0-9', 0.33], ['YES', 'Italy', '10-19', 0.47], ['YES', 'Italy', '20-29', 0.47], ['YES', 'Italy', '30-39', 0.47], ['YES', 'Italy', '40-49', 0.47],
              ['YES', 'Italy', '50-59', 0.47], ['YES', 'Italy', '60-69', 0.47], ['YES', 'Italy', '70-79', 0.47], ['YES', 'Italy', '80', 0.47],
              ['YES', 'China', '0-9', 0.33], ['YES', 'China', '10-19', 0.47], ['YES', 'China', '20-29', 0.47], ['YES', 'China', '30-39', 0.47], ['YES', 'China', '40-49', 0.47],
              ['YES', 'China', '50-59', 0.47], ['YES', 'China', '60-69', 0.47], ['YES', 'China', '70-79', 0.47],
              ['YES', 'China', '80', 0.47],
              ['NO', 'Italy', '0-9', 0.33], ['NO', 'Italy', '10-19', 0.47], ['NO', 'Italy', '20-29', 0.47],
              ['NO', 'Italy', '30-39', 0.47], ['NO', 'Italy', '40-49', 0.47], ['NO', 'Italy', '50-59', 0.47],
              ['NO', 'Italy', '60-69', 0.47], ['NO', 'Italy', '70-79', 0.47], ['NO', 'Italy', '80', 0.47],
              ['NO', 'China', '0-9', 0.33], ['NO', 'China', '10-19', 0.47], ['NO', 'China', '20-29', 0.47],
              ['NO', 'China', '30-39', 0.47], ['NO', 'China', '40-49', 0.47],
              ['NO', 'China', '50-59', 0.47], ['NO', 'China', '60-69', 0.47], ['NO', 'China', '70-79', 0.47],
              ['NO', 'China', '80', 0.47]]
    for i in range(0,len(values)):  #replace bogus values
        values[i][3] = fatalities[i]
    F2.add_values(values)

    causalModel = BN('COVID Model',
             [C, A, F],
             [F0, F1, F2])

    return causalModel


def CausalModelMediator():
    '''
   CausalModelMediator returns a DAG that is a Causal model that
   represents the joint distribution of value assignments to
   variables in COVID-19 data.
    '''
    ### READ IN THE DATA
    df = pd.read_csv('data/covid.csv')

    ### DOMAIN INFORMATION
    variable_domains = {
    "Age": ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80'],
    "Country": ['Italy', 'China'],
    "Fatality": ['YES', 'NO']
    }

    countC, countI, fatalitiesC, fatalitiesI = [], [], [], []
    for age in variable_domains["Age"]:
        countC.append(len(df[(df["Country"] == "China") &
                     (df["Age"] == age)]))
        countI.append(len(df[(df["Country"] == "Italy") &
                     (df["Age"] == age)]))
        temp = len(df[(df["Country"] == "China") &
                     (df["Age"] == age)  &
                     (df["Fatality"] == "YES")])
        fatalitiesC.append(temp/countC[-1])
        temp = len(df[(df["Country"] == "Italy") &
                     (df["Age"] == age)  &
                     (df["Fatality"] == "YES")])
        fatalitiesI.append(temp/countI[-1])
        # m_f_ratio = len(df[(df["Country"] == "China") &
        #                     (df["Age"] == age) &
        #                     (df["Fatality"] == "YES") & (df["Gender"] == ' Male')]) #more men die than women!!

    denom = sum(countC)
    countC = [val / denom for val in countC]
    denom = sum(countI)
    countI = [val / denom for val in countI]
    counts = countI + countC
    fatalitiesY = fatalitiesI + fatalitiesC
    fatalitiesN = [1 - val for val in fatalitiesY]
    fatalities = fatalitiesY + fatalitiesN

    C = Variable("Country", variable_domains["Country"])
    F0 = Factor("P(C)", [C])
    values = [['Italy', len(df[(df["Country"] == "Italy")])/df.shape[0]], ['China', len(df[(df["Country"] == "China")])/df.shape[0]]]
    F0.add_values(values)

    A = Variable("Age", variable_domains["Age"])
    F1 = Factor("P(A|C)", [A,C])
    #note probabilities that are initialized are bogus
    values = [['0-9', 'Italy', 0.33], ['10-19', 'Italy', 0.47], ['20-29', 'Italy', 0.47], ['30-39', 'Italy', 0.47], ['40-49', 'Italy', 0.47], ['50-59', 'Italy', 0.47], ['60-69', 'Italy', 0.47], ['70-79', 'Italy', 0.47], ['80', 'Italy', 0.47],
              ['0-9', 'China', 0.33], ['10-19', 'China', 0.47], ['20-29', 'China', 0.47], ['30-39', 'China', 0.47], ['40-49', 'China', 0.47], ['50-59', 'China', 0.47], ['60-69', 'China', 0.47], ['70-79', 'China', 0.47], ['80', 'China', 0.47]]
    for i in range(0,len(values)): #replace bogus values
        values[i][2] = counts[i]
    F1.add_values(values)

    F = Variable("Fatality", variable_domains["Fatality"])
    F2 = Factor("P(F|C,A)", [F,C,A])
    #note probabilities that are initialized are bogus
    values = [['YES', 'Italy', '0-9', 0.33], ['YES', 'Italy', '10-19', 0.47], ['YES', 'Italy', '20-29', 0.47], ['YES', 'Italy', '30-39', 0.47], ['YES', 'Italy', '40-49', 0.47],
              ['YES', 'Italy', '50-59', 0.47], ['YES', 'Italy', '60-69', 0.47], ['YES', 'Italy', '70-79', 0.47], ['YES', 'Italy', '80', 0.47],
              ['YES', 'China', '0-9', 0.33], ['YES', 'China', '10-19', 0.47], ['YES', 'China', '20-29', 0.47], ['YES', 'China', '30-39', 0.47], ['YES', 'China', '40-49', 0.47],
              ['YES', 'China', '50-59', 0.47], ['YES', 'China', '60-69', 0.47], ['YES', 'China', '70-79', 0.47],
              ['YES', 'China', '80', 0.47],
              ['NO', 'Italy', '0-9', 0.33], ['NO', 'Italy', '10-19', 0.47], ['NO', 'Italy', '20-29', 0.47],
              ['NO', 'Italy', '30-39', 0.47], ['NO', 'Italy', '40-49', 0.47], ['NO', 'Italy', '50-59', 0.47],
              ['NO', 'Italy', '60-69', 0.47], ['NO', 'Italy', '70-79', 0.47], ['NO', 'Italy', '80', 0.47],
              ['NO', 'China', '0-9', 0.33], ['NO', 'China', '10-19', 0.47], ['NO', 'China', '20-29', 0.47],
              ['NO', 'China', '30-39', 0.47], ['NO', 'China', '40-49', 0.47],
              ['NO', 'China', '50-59', 0.47], ['NO', 'China', '60-69', 0.47], ['NO', 'China', '70-79', 0.47],
              ['NO', 'China', '80', 0.47]]
    for i in range(0,len(values)):  #replace bogus values
        values[i][3] = fatalities[i]
    F2.add_values(values)

    causalModel = BN('COVID Model',
             [C, A, F],
             [F0, F1, F2])

    return causalModel

def all_fixed(vars, sample):
    for v in vars:
        if not v.name in sample:
            return False
    return True

#Implementation is super annoying!!
def SampleBN(Net, QueryVar, EvidenceVars):

    samples = []
    for i in range(0,1000):
        w = 1 #weight for this sample
        sample = {} #new sample
        for f in Net.factors(): #sample from all the priors
            if len(f.get_scope()) == 1: #prior
                if f.get_scope()[0] in EvidenceVars: #alter the weight
                    w = w*f.get_value_at_current_assignments()
                    sample[f.get_scope()[0].name] = f.get_scope()[0].get_evidence()
                    f.get_scope()[0].set_assignment(f.get_scope()[0].get_evidence())
                else: #sample
                    assignment = random.choices(f.get_scope()[0].domain(), weights=f.get_values(), k=1)
                    sample[f.get_scope()[0].name] = assignment[0]
                    f.get_scope()[0].set_assignment(assignment[0])

        while (not all_fixed(Net.variables(), sample)):
            for f in Net.factors():  # iterate over factors
                scopes = list(f.get_scope())
                if len(scopes) > 1 and scopes[0] in EvidenceVars and all_fixed(scopes[1:], sample): #alter the weight if var is in evidence
                    w = w*f.get_value_at_current_assignments()
                    sample[scopes[0].name] = scopes[0].get_evidence()
                    scopes[0].set_assignment(scopes[0].get_evidence())
                elif not scopes[0].name in sample and all_fixed(scopes[1:], sample): #else, sample
                    values = []
                    for d in scopes[0].domain():
                        scopes[0].set_assignment(d)
                        values.append(f.get_value_at_current_assignments())
                    # print(scopes[0].domain())
                    # print(values)
                    # input()
                    assignment = random.choices(scopes[0].domain(), weights=values, k=1)
                    scopes[0].set_assignment(assignment[0])
                    sample[scopes[0].name] = assignment[0]

        samples.append((sample, w))

    #now we have the samples.  Calculate the distribution for the QueryVar
    domvals = QueryVar.domain()
    probs = [0]*len(domvals)

    tot = 0
    for s in samples:
        c = 0
        point = s[0]
        w = s[1]
        #print(",".join(point.values()))
        for d in domvals:
            if point[QueryVar.name] == d:
                probs[c] += w
            c += 1
        tot += w

    probs = [p/tot for p in probs]
    return probs

if __name__ == "__main__":

    model = CausalModelMediator()
    Variables = model.variables()
    Factors = model.factors()

    Variables[0].set_evidence("Italy")
    probsExact1 = VE(model, Variables[2], [Variables[0]])
    for v in model.variables():
        v.reset_assignment() #in case we left things in a mess
    probsEstimated1 = SampleBN(model, Variables[2], [Variables[0]])

    Variables[0].set_evidence("China")
    for v in model.variables():
        v.reset_assignment()
    probsExact2 = VE(model, Variables[2], [Variables[0]])
    for v in model.variables():
        v.reset_assignment()
    probsEstimated2 = SampleBN(model, Variables[2], [Variables[0]])

    #CALCULATE TOTAL CAUSAL EFFECT
    TCE = probsExact1[0] - probsExact2[0] #CFR in Italy minus CFR in China
    print(f"Exact TCE (effect of changing from China to Italy) = {TCE}")

    TCE = probsEstimated1[0] - probsEstimated2[0] #CFR in Italy minus CFR in China
    print(f"Estimated TCE (effect of changing from China to Italy) = {TCE}")


    #But, what if Age was a confounder instead of a mediator?
    model = CausalModelConfounder() #We don't actually need to make a whole new model to do the estimation below.
    # But we could ask people to make an aternative model?  Like you'll get the same answer either way tho ...
    Variables = model.variables()

    ageprobs = VE(model, Variables[1], []) #probability of the different ages, regardless of country
    ageprobss = SampleBN(model, Variables[1], [])
    for age in ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80']:
        Variables[1].set_evidence(age)
        Variables[0].set_evidence("Italy")
        probsI = VE(model, Variables[2], [Variables[0], Variables[1]]) #P(Fatality|Italy, Age)
        probsIs = SampleBN(model, Variables[2], [Variables[0], Variables[1]]) #P(Fatality|Italy, Age)

        Variables[0].set_evidence("China")
        probsC = VE(model, Variables[2], [Variables[0], Variables[1]]) #P(Fatality|China, Age)
        probsCs = SampleBN(model, Variables[2], [Variables[0], Variables[1]]) #P(Fatality|Italy, Age)

    #CALCULATE ADJUSTED CAUSAL EFFECT
    italy = [a*b for a,b in zip(ageprobs,probsI)]
    china = [a*b for a, b in zip(ageprobs, probsC)]
    ACE = sum(italy) - sum(china) #Sum_over_age(P(Fatality|Italy, Age)*P(Age)) - Sum_over_age(P(Fatality|China, Age)*P(Age))
    print(f"Adjusted Causal Effect (assuming age is a confounding variable) = {ACE}")

    italy = [a*b for a,b in zip(ageprobss,probsIs)]
    china = [a*b for a, b in zip(ageprobss, probsCs)]
    ACE = sum(italy) - sum(china) #Sum_over_age(P(Fatality|Italy, Age)*P(Age)) - Sum_over_age(P(Fatality|China, Age)*P(Age))
    print(f"Estimated Adjusted Causal Effect (assuming age is a confounding variable) = {ACE}")





